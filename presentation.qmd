---
title: "HIST 414"
subtitle: "Understanding Canadian legal history through machine learning"
author: "Yash Mali, Anna Kovtunenko, Irene Berezin"
format: revealjs
scrollable: true
fontsize: 200%
theme: serif
---


## Introduction
Traditional approaches to text analysis of historical documents extensively rely on human coders for the analysis of documents, a process which is both time‐consuming, and prone to inter‐coder reliability issues: for example, different researchers may interpret the same passage in divergent ways, ways that are shaped by their own lived experiences that differ across the boad. Large language models (LLMs), by contrast, offer a more reproducible framework: while still biased, once trained or fine‐tuned on a corpus, they apply the same criteria uniformly across all texts, greatly reducing the variability introduced by multiple human annotators. 

## Introduction
However, as mentioned, LLMs themselves, by construction, absorb and reproduce biases present in the training data...

:::{.columns}
::: {.column width="40%"}
![](example_hist_414.png){width="100%"}
:::

::: {.column width="60%"}
***What if, instead of viewing this as a flaw, we could harness those embedded biases to uncover latent trends in text corpora?*** identifying, for instance, how certain groups have been described or which issues were emphasized over time.
:::

:::



## Notebook 1: 
**Learning Outcomes**: Through this class, students will...

- Understand how how implicit bias can be ingrained in words embeddings when trained on a given corpus of text, and how we can use that bias to our advantage to discover implicit racial or gender-based biases in judicial decisions and court cases.
- Answer an existing research question by following through and recreating the methodology of a published paper in the field of historical legal research, using a novel dataset.
- Learn to present model outputs in ways that are meaningful and credible to historians and legal scholars.

## Why is this important?

Little academic research exists on analyzing the implicit biases found within the judiciary, particularly in relation to the language used in judicial opinions. When looking for case studies to analyze for this course, we could not find a single study analyzing identity bias in Canadian court decisions using any sort of machine learning technique. We hence consider this to be an open area of research that would make for an interesting demo for students and potentially inspire them to look more closely at this issue in their own personal projects. 

## Key Features and Results

:::{.columns}
::: {.column width="30%"}
![](racism_in_legal_texts.png){width="100%"}
:::

::: {.column width="70%"}
Using word-embeddings and statistical methods, our aim will be to create a hands-on demo, consisting of a mix of theory and application, which will loosely replicate an existing American case study of implicit bias in supreme court decisions. 
:::

:::

In class, we will try to answer *"to what extent, across time, are Canadian supreme court judges more likely to associate unpleasant terms with African-American/Indigenous names, and pleasant terms with white/non-indigenous names in their written opinions?"*

## Notebook 2: 
**Learning Outcomes**: Through this class, students will...

- Understand how computational tools like topic modeling can offer new ways to explore and interpret historical court judgments, especially when analyzing how certain constitutional issues were discussed across time.
- Make and support historical arguments about the constitutional concerns which dominated a particular period by identifying recurring themes in judicial decisions and connecting them to broader historical contexts.
- Reflect on the strengths and limitations of using computational methods in historical research, and critique how such methods may shape, support, or obscure scholarly interpretations of constitutional history

## Why is this important?

Existing research has used topic modeling to trace constitutional themes in U.S. legal texts, but similar analysis of Canadian Supreme Court decisions remains limited. As grasping high-level, temporal patterns or shifts in legal reasoning is difficult in traditional analysis, without topic modelling, this lesson helps students identify broad patterns in legal reasoning over time, opening new avenues for historical inquiry. It encourages critical thinking about how national events and social change have shaped constitutional interpretation in Canada.

## Key Features and Results

:::{.columns}
::: {.column width="40%"}
![](supreme_court_topics_over_time.png){width="100%"}
:::

::: {.column width="60%"}
Using topic modeling and visual tools like word clouds and intertopic distance maps, this hands-on demo combines theory and application to explore how constitutional issues appear and shift across Supreme Court of Canada decisions.
:::

:::

In class, we will ask: *“What dominant legal themes emerge in rulings from a given time period, and how might national events have influenced their prominence?”*


## Notebook 3

**Learning Outcomes**: Through this class, students will...

- Understand how word embeddings can be used to study bias in Supreme Court of Canada cases.
- Use word embeddings to observe and quantify bias evolving through time in the Supreme Court of Canada cases.
- Learn about what word embeddings are, how they work, and how they can be used to represent words ingrained with context.
- Learn about the operations you can perform on word embeddings what they imply.
- Learn when *not* to use word embeddings, and how to interpret them with caution.

## Class Structure

Use the Supreme Court of Canada Bulk Decisions Dataset.

1. Out of 1877 to 2024 pick a very pivotal time in canadian justice history.
2. Say we pick 1960. Train a word embedding model on the Supreme Court of Canada cases from 1877 to 1960 and another one from 1960 to 2024.
3. Compare the two models to see how the word embeddings have changed over time.
4. For example, use word embedding association tests to measure gender or race bias shifting.

## Key Features

Quantifying bias over time. Perhaps we will see the opposite because recent years will have more data and older years will have less reliable data.

:::{.columns}
::: {.column width="65%"}
![](temporal_bias.png)
:::
:::


